{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Functional API implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Multiple-input and Multiple-output (auxiliary-output) architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For wide and deep path, choosing 5 features[0:4] through the wide path and choosing 6 features[2:7] through the deep path\n",
    "\n",
    "input_A = keras.layers.Input(shape=[5], name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6], name='deep_path')\n",
    "hidden_1 = keras.layers.Dense(50, activation=\"relu\")(input_B)\n",
    "hidden_2 = keras.layers.Dense(40, activation=\"relu\")(hidden_1)\n",
    "concat = keras.layers.concatenate([input_A, hidden_2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden_2)\n",
    "\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2 inputs and 2 outputs required\n",
    "# since both inputs were defined with different features so creating new inputs accordingly\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "# new labels should be provided for all newly defined auxiliary outputs, but since in the model both the (old and new outputs) should try to predict same thing so we  directly passing 'y_train' twice instead of creating 'y_train_A' & 'y_train_B' explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if a single loss= ... is passed then it will be applied to both the outputs, but main_output needs to have more weightage so loss_weight= ...\n",
    "\n",
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "363/363 [==============================] - 3s 5ms/step - loss: 0.9785 - output_loss: 0.8788 - aux_output_loss: 1.8762 - val_loss: 0.6396 - val_output_loss: 0.5754 - val_aux_output_loss: 1.2172\n",
      "Epoch 2/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5703 - output_loss: 0.5137 - aux_output_loss: 1.0796 - val_loss: 0.5488 - val_output_loss: 0.4998 - val_aux_output_loss: 0.9900\n",
      "Epoch 3/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.5267 - output_loss: 0.4821 - aux_output_loss: 0.9281 - val_loss: 0.5172 - val_output_loss: 0.4748 - val_aux_output_loss: 0.8990\n",
      "Epoch 4/25\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4749 - output_loss: 0.4370 - aux_output_loss: 0.8156 - val_loss: 0.4763 - val_output_loss: 0.4423 - val_aux_output_loss: 0.7828\n",
      "Epoch 5/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4544 - output_loss: 0.4232 - aux_output_loss: 0.7353 - val_loss: 0.4628 - val_output_loss: 0.4338 - val_aux_output_loss: 0.7244\n",
      "Epoch 6/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4403 - output_loss: 0.4135 - aux_output_loss: 0.6815 - val_loss: 0.4556 - val_output_loss: 0.4304 - val_aux_output_loss: 0.6824\n",
      "Epoch 7/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4302 - output_loss: 0.4062 - aux_output_loss: 0.6465 - val_loss: 0.4333 - val_output_loss: 0.4094 - val_aux_output_loss: 0.6483\n",
      "Epoch 8/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4197 - output_loss: 0.3978 - aux_output_loss: 0.6168 - val_loss: 0.4353 - val_output_loss: 0.4136 - val_aux_output_loss: 0.6300\n",
      "Epoch 9/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4179 - output_loss: 0.3965 - aux_output_loss: 0.6106 - val_loss: 0.4272 - val_output_loss: 0.4080 - val_aux_output_loss: 0.5999\n",
      "Epoch 10/25\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4044 - output_loss: 0.3850 - aux_output_loss: 0.5785 - val_loss: 0.4221 - val_output_loss: 0.4041 - val_aux_output_loss: 0.5840\n",
      "Epoch 11/25\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.4395 - output_loss: 0.4203 - aux_output_loss: 0.6120 - val_loss: 0.4535 - val_output_loss: 0.4382 - val_aux_output_loss: 0.5905\n",
      "Epoch 12/25\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.4064 - output_loss: 0.3882 - aux_output_loss: 0.5701 - val_loss: 0.4277 - val_output_loss: 0.4123 - val_aux_output_loss: 0.5663\n",
      "Epoch 13/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3941 - output_loss: 0.3766 - aux_output_loss: 0.5522 - val_loss: 0.4192 - val_output_loss: 0.4042 - val_aux_output_loss: 0.5543\n",
      "Epoch 14/25\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3876 - output_loss: 0.3706 - aux_output_loss: 0.5406 - val_loss: 0.3936 - val_output_loss: 0.3771 - val_aux_output_loss: 0.5422\n",
      "Epoch 15/25\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3802 - output_loss: 0.3636 - aux_output_loss: 0.5298 - val_loss: 0.3997 - val_output_loss: 0.3844 - val_aux_output_loss: 0.5381\n",
      "Epoch 16/25\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3777 - output_loss: 0.3612 - aux_output_loss: 0.5261 - val_loss: 0.4238 - val_output_loss: 0.4111 - val_aux_output_loss: 0.5386\n",
      "Epoch 17/25\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3832 - output_loss: 0.3682 - aux_output_loss: 0.5174 - val_loss: 0.3863 - val_output_loss: 0.3711 - val_aux_output_loss: 0.5236\n",
      "Epoch 18/25\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3692 - output_loss: 0.3538 - aux_output_loss: 0.5073 - val_loss: 0.3840 - val_output_loss: 0.3681 - val_aux_output_loss: 0.5269\n",
      "Epoch 19/25\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3654 - output_loss: 0.3505 - aux_output_loss: 0.4997 - val_loss: 0.4093 - val_output_loss: 0.3962 - val_aux_output_loss: 0.5272\n",
      "Epoch 20/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3654 - output_loss: 0.3511 - aux_output_loss: 0.4945 - val_loss: 0.3990 - val_output_loss: 0.3871 - val_aux_output_loss: 0.5063\n",
      "Epoch 21/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3662 - output_loss: 0.3523 - aux_output_loss: 0.4917 - val_loss: 0.3727 - val_output_loss: 0.3590 - val_aux_output_loss: 0.4966\n",
      "Epoch 22/25\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3567 - output_loss: 0.3428 - aux_output_loss: 0.4823 - val_loss: 0.3695 - val_output_loss: 0.3565 - val_aux_output_loss: 0.4859\n",
      "Epoch 23/25\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3552 - output_loss: 0.3418 - aux_output_loss: 0.4752 - val_loss: 0.3639 - val_output_loss: 0.3505 - val_aux_output_loss: 0.4840\n",
      "Epoch 24/25\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3488 - output_loss: 0.3354 - aux_output_loss: 0.4688 - val_loss: 0.3716 - val_output_loss: 0.3582 - val_aux_output_loss: 0.4915\n",
      "Epoch 25/25\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3481 - output_loss: 0.3352 - aux_output_loss: 0.4648 - val_loss: 0.3573 - val_output_loss: 0.3446 - val_aux_output_loss: 0.4715\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=25, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 3ms/step - loss: 0.3465 - output_loss: 0.3330 - aux_output_loss: 0.4686\n"
     ]
    }
   ],
   "source": [
    "# we get total loss and individual losses as well\n",
    "\n",
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 151ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Saving and Restoring the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")\n",
    "\n",
    "# this can save all the parameters, hyperparameters and optimizers for 'Sequential' and 'Functional' APIs. (not for Subclassing APIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ModelCheckpoint Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelcheckpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True, monitor='val_loss', mode='min', verbose=1)\n",
    "\n",
    "# if save_best_only = False (default), then we will have a checkpoint after each epoch (by default) hence provide a formate to save each of those files preferably in the order of {epoch_no}_{val_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.3458 - output_loss: 0.3332 - aux_output_loss: 0.4594\n",
      "Epoch 1: val_loss improved from inf to 0.36718, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3459 - output_loss: 0.3333 - aux_output_loss: 0.4595 - val_loss: 0.3672 - val_output_loss: 0.3553 - val_aux_output_loss: 0.4745\n",
      "Epoch 2/25\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.3434 - output_loss: 0.3310 - aux_output_loss: 0.4549\n",
      "Epoch 2: val_loss improved from 0.36718 to 0.36053, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3433 - output_loss: 0.3309 - aux_output_loss: 0.4553 - val_loss: 0.3605 - val_output_loss: 0.3493 - val_aux_output_loss: 0.4614\n",
      "Epoch 3/25\n",
      "351/363 [============================>.] - ETA: 0s - loss: 0.3428 - output_loss: 0.3306 - aux_output_loss: 0.4519\n",
      "Epoch 3: val_loss did not improve from 0.36053\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3422 - output_loss: 0.3301 - aux_output_loss: 0.4516 - val_loss: 0.3628 - val_output_loss: 0.3509 - val_aux_output_loss: 0.4694\n",
      "Epoch 4/25\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.3392 - output_loss: 0.3272 - aux_output_loss: 0.4467\n",
      "Epoch 4: val_loss improved from 0.36053 to 0.35855, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3387 - output_loss: 0.3268 - aux_output_loss: 0.4463 - val_loss: 0.3586 - val_output_loss: 0.3482 - val_aux_output_loss: 0.4515\n",
      "Epoch 5/25\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.3387 - output_loss: 0.3272 - aux_output_loss: 0.4423\n",
      "Epoch 5: val_loss improved from 0.35855 to 0.35462, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3387 - output_loss: 0.3272 - aux_output_loss: 0.4423 - val_loss: 0.3546 - val_output_loss: 0.3431 - val_aux_output_loss: 0.4585\n",
      "Epoch 6/25\n",
      "345/363 [===========================>..] - ETA: 0s - loss: 0.3400 - output_loss: 0.3287 - aux_output_loss: 0.4418\n",
      "Epoch 6: val_loss improved from 0.35462 to 0.34498, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3378 - output_loss: 0.3267 - aux_output_loss: 0.4383 - val_loss: 0.3450 - val_output_loss: 0.3340 - val_aux_output_loss: 0.4439\n",
      "Epoch 7/25\n",
      "353/363 [============================>.] - ETA: 0s - loss: 0.3483 - output_loss: 0.3372 - aux_output_loss: 0.4479\n",
      "Epoch 7: val_loss did not improve from 0.34498\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3521 - output_loss: 0.3412 - aux_output_loss: 0.4502 - val_loss: 0.6673 - val_output_loss: 0.6647 - val_aux_output_loss: 0.6900\n",
      "Epoch 8/25\n",
      "343/363 [===========================>..] - ETA: 0s - loss: 0.3488 - output_loss: 0.3380 - aux_output_loss: 0.4458\n",
      "Epoch 8: val_loss did not improve from 0.34498\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3489 - output_loss: 0.3381 - aux_output_loss: 0.4466 - val_loss: 0.3629 - val_output_loss: 0.3530 - val_aux_output_loss: 0.4519\n",
      "Epoch 9/25\n",
      "346/363 [===========================>..] - ETA: 0s - loss: 0.3385 - output_loss: 0.3280 - aux_output_loss: 0.4329\n",
      "Epoch 9: val_loss improved from 0.34498 to 0.34464, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3383 - output_loss: 0.3278 - aux_output_loss: 0.4321 - val_loss: 0.3446 - val_output_loss: 0.3341 - val_aux_output_loss: 0.4398\n",
      "Epoch 10/25\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.3343 - output_loss: 0.3240 - aux_output_loss: 0.4271\n",
      "Epoch 10: val_loss did not improve from 0.34464\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3337 - output_loss: 0.3234 - aux_output_loss: 0.4265 - val_loss: 0.3559 - val_output_loss: 0.3469 - val_aux_output_loss: 0.4366\n",
      "Epoch 11/25\n",
      "344/363 [===========================>..] - ETA: 0s - loss: 0.3324 - output_loss: 0.3221 - aux_output_loss: 0.4251\n",
      "Epoch 11: val_loss did not improve from 0.34464\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3325 - output_loss: 0.3223 - aux_output_loss: 0.4242 - val_loss: 0.3458 - val_output_loss: 0.3359 - val_aux_output_loss: 0.4353\n",
      "Epoch 12/25\n",
      "362/363 [============================>.] - ETA: 0s - loss: 0.3314 - output_loss: 0.3214 - aux_output_loss: 0.4208\n",
      "Epoch 12: val_loss improved from 0.34464 to 0.33946, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3312 - output_loss: 0.3213 - aux_output_loss: 0.4206 - val_loss: 0.3395 - val_output_loss: 0.3297 - val_aux_output_loss: 0.4274\n",
      "Epoch 13/25\n",
      "355/363 [============================>.] - ETA: 0s - loss: 0.3314 - output_loss: 0.3216 - aux_output_loss: 0.4200\n",
      "Epoch 13: val_loss did not improve from 0.33946\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3292 - output_loss: 0.3194 - aux_output_loss: 0.4180 - val_loss: 0.3443 - val_output_loss: 0.3349 - val_aux_output_loss: 0.4292\n",
      "Epoch 14/25\n",
      "357/363 [============================>.] - ETA: 0s - loss: 0.3332 - output_loss: 0.3240 - aux_output_loss: 0.4163\n",
      "Epoch 14: val_loss did not improve from 0.33946\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3327 - output_loss: 0.3235 - aux_output_loss: 0.4160 - val_loss: 0.3620 - val_output_loss: 0.3540 - val_aux_output_loss: 0.4332\n",
      "Epoch 15/25\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.3318 - output_loss: 0.3227 - aux_output_loss: 0.4142\n",
      "Epoch 15: val_loss did not improve from 0.33946\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3312 - output_loss: 0.3220 - aux_output_loss: 0.4135 - val_loss: 0.3485 - val_output_loss: 0.3397 - val_aux_output_loss: 0.4280\n",
      "Epoch 16/25\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.3293 - output_loss: 0.3201 - aux_output_loss: 0.4129\n",
      "Epoch 16: val_loss did not improve from 0.33946\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3286 - output_loss: 0.3193 - aux_output_loss: 0.4119 - val_loss: 0.3429 - val_output_loss: 0.3340 - val_aux_output_loss: 0.4230\n",
      "Epoch 17/25\n",
      "348/363 [===========================>..] - ETA: 0s - loss: 0.3278 - output_loss: 0.3189 - aux_output_loss: 0.4079\n",
      "Epoch 17: val_loss did not improve from 0.33946\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3272 - output_loss: 0.3181 - aux_output_loss: 0.4089 - val_loss: 0.3467 - val_output_loss: 0.3385 - val_aux_output_loss: 0.4205\n",
      "Epoch 18/25\n",
      "351/363 [============================>.] - ETA: 0s - loss: 0.3256 - output_loss: 0.3166 - aux_output_loss: 0.4068\n",
      "Epoch 18: val_loss did not improve from 0.33946\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3262 - output_loss: 0.3172 - aux_output_loss: 0.4068 - val_loss: 0.3395 - val_output_loss: 0.3309 - val_aux_output_loss: 0.4167\n",
      "Epoch 19/25\n",
      "344/363 [===========================>..] - ETA: 0s - loss: 0.3236 - output_loss: 0.3146 - aux_output_loss: 0.4050\n",
      "Epoch 19: val_loss improved from 0.33946 to 0.33563, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3227 - output_loss: 0.3136 - aux_output_loss: 0.4039 - val_loss: 0.3356 - val_output_loss: 0.3267 - val_aux_output_loss: 0.4162\n",
      "Epoch 20/25\n",
      "354/363 [============================>.] - ETA: 0s - loss: 0.3247 - output_loss: 0.3158 - aux_output_loss: 0.4051\n",
      "Epoch 20: val_loss improved from 0.33563 to 0.33422, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3236 - output_loss: 0.3148 - aux_output_loss: 0.4033 - val_loss: 0.3342 - val_output_loss: 0.3255 - val_aux_output_loss: 0.4125\n",
      "Epoch 21/25\n",
      "352/363 [============================>.] - ETA: 0s - loss: 0.3259 - output_loss: 0.3172 - aux_output_loss: 0.4043\n",
      "Epoch 21: val_loss did not improve from 0.33422\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3241 - output_loss: 0.3154 - aux_output_loss: 0.4025 - val_loss: 0.3405 - val_output_loss: 0.3328 - val_aux_output_loss: 0.4105\n",
      "Epoch 22/25\n",
      "354/363 [============================>.] - ETA: 0s - loss: 0.3238 - output_loss: 0.3152 - aux_output_loss: 0.4014\n",
      "Epoch 22: val_loss improved from 0.33422 to 0.33353, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3229 - output_loss: 0.3142 - aux_output_loss: 0.4009 - val_loss: 0.3335 - val_output_loss: 0.3252 - val_aux_output_loss: 0.4089\n",
      "Epoch 23/25\n",
      "342/363 [===========================>..] - ETA: 0s - loss: 0.3266 - output_loss: 0.3181 - aux_output_loss: 0.4022\n",
      "Epoch 23: val_loss improved from 0.33353 to 0.33253, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3244 - output_loss: 0.3160 - aux_output_loss: 0.3995 - val_loss: 0.3325 - val_output_loss: 0.3244 - val_aux_output_loss: 0.4053\n",
      "Epoch 24/25\n",
      "362/363 [============================>.] - ETA: 0s - loss: 0.3302 - output_loss: 0.3219 - aux_output_loss: 0.4048\n",
      "Epoch 24: val_loss did not improve from 0.33253\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3304 - output_loss: 0.3221 - aux_output_loss: 0.4050 - val_loss: 0.3463 - val_output_loss: 0.3378 - val_aux_output_loss: 0.4225\n",
      "Epoch 25/25\n",
      "346/363 [===========================>..] - ETA: 0s - loss: 0.3176 - output_loss: 0.3094 - aux_output_loss: 0.3922\n",
      "Epoch 25: val_loss did not improve from 0.33253\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3203 - output_loss: 0.3120 - aux_output_loss: 0.3951 - val_loss: 0.3361 - val_output_loss: 0.3285 - val_aux_output_loss: 0.4046\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=25, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), callbacks=[modelcheckpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_keras_model.h5\")\n",
    "\n",
    "# rolling back to the best model with 'minimum' 'val_loss' value saved and overwritten as 'my_keras_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3459203839302063,\n",
       "  0.343308687210083,\n",
       "  0.34223008155822754,\n",
       "  0.3387058675289154,\n",
       "  0.3387146592140198,\n",
       "  0.3378479778766632,\n",
       "  0.3521268665790558,\n",
       "  0.3489410877227783,\n",
       "  0.33826178312301636,\n",
       "  0.33370441198349,\n",
       "  0.33250391483306885,\n",
       "  0.33119872212409973,\n",
       "  0.3292163908481598,\n",
       "  0.3327263593673706,\n",
       "  0.331166535615921,\n",
       "  0.3285514712333679,\n",
       "  0.3271704614162445,\n",
       "  0.3261755406856537,\n",
       "  0.32267045974731445,\n",
       "  0.3236371576786041,\n",
       "  0.3240714371204376,\n",
       "  0.32286536693573,\n",
       "  0.3243517279624939,\n",
       "  0.33035773038864136,\n",
       "  0.3203165829181671],\n",
       " 'output_loss': [0.33330368995666504,\n",
       "  0.3308705687522888,\n",
       "  0.3300817310810089,\n",
       "  0.3267561197280884,\n",
       "  0.3272000551223755,\n",
       "  0.3266880512237549,\n",
       "  0.341232568025589,\n",
       "  0.33809301257133484,\n",
       "  0.32783061265945435,\n",
       "  0.32338839769363403,\n",
       "  0.3223128914833069,\n",
       "  0.3212641775608063,\n",
       "  0.3193570375442505,\n",
       "  0.3234739899635315,\n",
       "  0.3220181167125702,\n",
       "  0.3192876875400543,\n",
       "  0.3180919885635376,\n",
       "  0.3172188997268677,\n",
       "  0.3136448860168457,\n",
       "  0.3147883117198944,\n",
       "  0.3153575360774994,\n",
       "  0.3141929805278778,\n",
       "  0.31599894165992737,\n",
       "  0.322062611579895,\n",
       "  0.3120124340057373],\n",
       " 'aux_output_loss': [0.45947152376174927,\n",
       "  0.4552516043186188,\n",
       "  0.45156705379486084,\n",
       "  0.446256548166275,\n",
       "  0.44234800338745117,\n",
       "  0.4382873773574829,\n",
       "  0.4501735270023346,\n",
       "  0.4465760588645935,\n",
       "  0.43214547634124756,\n",
       "  0.4265471398830414,\n",
       "  0.42422187328338623,\n",
       "  0.4206100404262543,\n",
       "  0.4179510474205017,\n",
       "  0.41599804162979126,\n",
       "  0.4135003685951233,\n",
       "  0.4119236171245575,\n",
       "  0.40887701511383057,\n",
       "  0.4067855179309845,\n",
       "  0.40390241146087646,\n",
       "  0.4032771587371826,\n",
       "  0.40249305963516235,\n",
       "  0.4009174704551697,\n",
       "  0.3995278775691986,\n",
       "  0.40501484274864197,\n",
       "  0.39505478739738464],\n",
       " 'val_loss': [0.36717769503593445,\n",
       "  0.3605320155620575,\n",
       "  0.36278483271598816,\n",
       "  0.3585509657859802,\n",
       "  0.3546241223812103,\n",
       "  0.34498369693756104,\n",
       "  0.6672545671463013,\n",
       "  0.36287352442741394,\n",
       "  0.3446365296840668,\n",
       "  0.3559158742427826,\n",
       "  0.3458450734615326,\n",
       "  0.33945849537849426,\n",
       "  0.344337522983551,\n",
       "  0.3619588017463684,\n",
       "  0.3485063910484314,\n",
       "  0.34291544556617737,\n",
       "  0.34670916199684143,\n",
       "  0.33948734402656555,\n",
       "  0.3356345593929291,\n",
       "  0.3342197835445404,\n",
       "  0.3405238687992096,\n",
       "  0.3335317373275757,\n",
       "  0.3325326442718506,\n",
       "  0.3462848961353302,\n",
       "  0.33610859513282776],\n",
       " 'val_output_loss': [0.3552531898021698,\n",
       "  0.34932225942611694,\n",
       "  0.3509337902069092,\n",
       "  0.34822186827659607,\n",
       "  0.3430849015712738,\n",
       "  0.3339901268482208,\n",
       "  0.6647292375564575,\n",
       "  0.35298389196395874,\n",
       "  0.3340633511543274,\n",
       "  0.3469490706920624,\n",
       "  0.33590641617774963,\n",
       "  0.32968834042549133,\n",
       "  0.3349049389362335,\n",
       "  0.35404422879219055,\n",
       "  0.3396740257740021,\n",
       "  0.3340122103691101,\n",
       "  0.3385082483291626,\n",
       "  0.33090877532958984,\n",
       "  0.32668250799179077,\n",
       "  0.3255167603492737,\n",
       "  0.3327513039112091,\n",
       "  0.32516178488731384,\n",
       "  0.32444629073143005,\n",
       "  0.33781933784484863,\n",
       "  0.3284933567047119],\n",
       " 'val_aux_output_loss': [0.47449713945388794,\n",
       "  0.46141931414604187,\n",
       "  0.4694444239139557,\n",
       "  0.45151254534721375,\n",
       "  0.4584774374961853,\n",
       "  0.4439253807067871,\n",
       "  0.6899818778038025,\n",
       "  0.4518805742263794,\n",
       "  0.43979567289352417,\n",
       "  0.4366180896759033,\n",
       "  0.435292512178421,\n",
       "  0.4273886978626251,\n",
       "  0.4292311668395996,\n",
       "  0.433189332485199,\n",
       "  0.42799708247184753,\n",
       "  0.4230450987815857,\n",
       "  0.4205175042152405,\n",
       "  0.41669556498527527,\n",
       "  0.4162020683288574,\n",
       "  0.41254571080207825,\n",
       "  0.4104791283607483,\n",
       "  0.40886178612709045,\n",
       "  0.40530943870544434,\n",
       "  0.42247578501701355,\n",
       "  0.40464556217193604]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### EarlyStopping Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## EarlyStopping callback interrupts training if no progress on val_set for a given no. of epochs (patience number) and roll backs to the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, monitor='val_loss', restore_best_weights=True, verbose=1)\n",
    "# 'restore_best_weights = True' to restore model weights from the epoch with the best value of the monitored quantity. If False, the model weights obtained at the last step of training are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "347/363 [===========================>..] - ETA: 0s - loss: 0.3013 - output_loss: 0.2949 - aux_output_loss: 0.3594\n",
      "Epoch 1: val_loss did not improve from 0.31522\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3025 - output_loss: 0.2960 - aux_output_loss: 0.3611 - val_loss: 0.3212 - val_output_loss: 0.3153 - val_aux_output_loss: 0.3741\n",
      "Epoch 2/100\n",
      "347/363 [===========================>..] - ETA: 0s - loss: 0.3035 - output_loss: 0.2968 - aux_output_loss: 0.3635\n",
      "Epoch 2: val_loss did not improve from 0.31522\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3052 - output_loss: 0.2987 - aux_output_loss: 0.3643 - val_loss: 0.3275 - val_output_loss: 0.3217 - val_aux_output_loss: 0.3793\n",
      "Epoch 3/100\n",
      "354/363 [============================>.] - ETA: 0s - loss: 0.3014 - output_loss: 0.2948 - aux_output_loss: 0.3612\n",
      "Epoch 3: val_loss did not improve from 0.31522\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3016 - output_loss: 0.2950 - aux_output_loss: 0.3606 - val_loss: 0.3261 - val_output_loss: 0.3209 - val_aux_output_loss: 0.3730\n",
      "Epoch 4/100\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.3012 - output_loss: 0.2946 - aux_output_loss: 0.3601\n",
      "Epoch 4: val_loss did not improve from 0.31522\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3008 - output_loss: 0.2943 - aux_output_loss: 0.3598 - val_loss: 0.3313 - val_output_loss: 0.3265 - val_aux_output_loss: 0.3741\n",
      "Epoch 5/100\n",
      "359/363 [============================>.] - ETA: 0s - loss: 0.3017 - output_loss: 0.2956 - aux_output_loss: 0.3574\n",
      "Epoch 5: val_loss did not improve from 0.31522\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3034 - output_loss: 0.2971 - aux_output_loss: 0.3595 - val_loss: 0.3192 - val_output_loss: 0.3136 - val_aux_output_loss: 0.3694\n",
      "Epoch 6/100\n",
      "357/363 [============================>.] - ETA: 0s - loss: 0.2986 - output_loss: 0.2922 - aux_output_loss: 0.3566\n",
      "Epoch 6: val_loss did not improve from 0.31522\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3002 - output_loss: 0.2938 - aux_output_loss: 0.3582 - val_loss: 0.3254 - val_output_loss: 0.3196 - val_aux_output_loss: 0.3785\n",
      "Epoch 7/100\n",
      "354/363 [============================>.] - ETA: 0s - loss: 0.3011 - output_loss: 0.2946 - aux_output_loss: 0.3595\n",
      "Epoch 7: val_loss did not improve from 0.31522\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2997 - output_loss: 0.2933 - aux_output_loss: 0.3579 - val_loss: 0.3153 - val_output_loss: 0.3094 - val_aux_output_loss: 0.3679\n",
      "Epoch 8/100\n",
      "357/363 [============================>.] - ETA: 0s - loss: 0.3038 - output_loss: 0.2978 - aux_output_loss: 0.3577\n",
      "Epoch 8: val_loss did not improve from 0.31522\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3047 - output_loss: 0.2985 - aux_output_loss: 0.3605 - val_loss: 0.3160 - val_output_loss: 0.3102 - val_aux_output_loss: 0.3685\n",
      "Epoch 9/100\n",
      "355/363 [============================>.] - ETA: 0s - loss: 0.3006 - output_loss: 0.2943 - aux_output_loss: 0.3572\n",
      "Epoch 9: val_loss did not improve from 0.31522\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3003 - output_loss: 0.2940 - aux_output_loss: 0.3574 - val_loss: 0.3168 - val_output_loss: 0.3106 - val_aux_output_loss: 0.3729\n",
      "Epoch 10/100\n",
      "362/363 [============================>.] - ETA: 0s - loss: 0.2999 - output_loss: 0.2935 - aux_output_loss: 0.3580\n",
      "Epoch 10: val_loss improved from 0.31522 to 0.31452, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2997 - output_loss: 0.2933 - aux_output_loss: 0.3578 - val_loss: 0.3145 - val_output_loss: 0.3086 - val_aux_output_loss: 0.3675\n",
      "Epoch 11/100\n",
      "362/363 [============================>.] - ETA: 0s - loss: 0.3025 - output_loss: 0.2962 - aux_output_loss: 0.3589\n",
      "Epoch 11: val_loss did not improve from 0.31452\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.3033 - output_loss: 0.2971 - aux_output_loss: 0.3592 - val_loss: 0.3573 - val_output_loss: 0.3537 - val_aux_output_loss: 0.3895\n",
      "Epoch 12/100\n",
      "362/363 [============================>.] - ETA: 0s - loss: 0.3050 - output_loss: 0.2987 - aux_output_loss: 0.3612\n",
      "Epoch 12: val_loss did not improve from 0.31452\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3059 - output_loss: 0.2997 - aux_output_loss: 0.3620 - val_loss: 0.3231 - val_output_loss: 0.3172 - val_aux_output_loss: 0.3769\n",
      "Epoch 13/100\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.2988 - output_loss: 0.2923 - aux_output_loss: 0.3571\n",
      "Epoch 13: val_loss did not improve from 0.31452\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2991 - output_loss: 0.2926 - aux_output_loss: 0.3575 - val_loss: 0.3221 - val_output_loss: 0.3169 - val_aux_output_loss: 0.3696\n",
      "Epoch 14/100\n",
      "349/363 [===========================>..] - ETA: 0s - loss: 0.3063 - output_loss: 0.3001 - aux_output_loss: 0.3619\n",
      "Epoch 14: val_loss improved from 0.31452 to 0.31137, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3045 - output_loss: 0.2983 - aux_output_loss: 0.3598 - val_loss: 0.3114 - val_output_loss: 0.3051 - val_aux_output_loss: 0.3678\n",
      "Epoch 15/100\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.3006 - output_loss: 0.2942 - aux_output_loss: 0.3579\n",
      "Epoch 15: val_loss did not improve from 0.31137\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2994 - output_loss: 0.2931 - aux_output_loss: 0.3566 - val_loss: 0.3153 - val_output_loss: 0.3097 - val_aux_output_loss: 0.3660\n",
      "Epoch 16/100\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.2979 - output_loss: 0.2914 - aux_output_loss: 0.3562\n",
      "Epoch 16: val_loss did not improve from 0.31137\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2984 - output_loss: 0.2919 - aux_output_loss: 0.3567 - val_loss: 0.3121 - val_output_loss: 0.3061 - val_aux_output_loss: 0.3659\n",
      "Epoch 17/100\n",
      "353/363 [============================>.] - ETA: 0s - loss: 0.2993 - output_loss: 0.2929 - aux_output_loss: 0.3572\n",
      "Epoch 17: val_loss did not improve from 0.31137\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2993 - output_loss: 0.2929 - aux_output_loss: 0.3568 - val_loss: 0.3143 - val_output_loss: 0.3087 - val_aux_output_loss: 0.3645\n",
      "Epoch 18/100\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.2985 - output_loss: 0.2920 - aux_output_loss: 0.3564\n",
      "Epoch 18: val_loss did not improve from 0.31137\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.2974 - output_loss: 0.2910 - aux_output_loss: 0.3552 - val_loss: 0.3305 - val_output_loss: 0.3264 - val_aux_output_loss: 0.3677\n",
      "Epoch 19/100\n",
      "355/363 [============================>.] - ETA: 0s - loss: 0.2988 - output_loss: 0.2923 - aux_output_loss: 0.3573\n",
      "Epoch 19: val_loss did not improve from 0.31137\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2986 - output_loss: 0.2922 - aux_output_loss: 0.3561 - val_loss: 0.3162 - val_output_loss: 0.3104 - val_aux_output_loss: 0.3685\n",
      "Epoch 20/100\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.2961 - output_loss: 0.2897 - aux_output_loss: 0.3539\n",
      "Epoch 20: val_loss did not improve from 0.31137\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2968 - output_loss: 0.2904 - aux_output_loss: 0.3544 - val_loss: 0.3264 - val_output_loss: 0.3208 - val_aux_output_loss: 0.3764\n",
      "Epoch 21/100\n",
      "353/363 [============================>.] - ETA: 0s - loss: 0.3054 - output_loss: 0.2993 - aux_output_loss: 0.3603\n",
      "Epoch 21: val_loss did not improve from 0.31137\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.3044 - output_loss: 0.2983 - aux_output_loss: 0.3598 - val_loss: 0.3172 - val_output_loss: 0.3109 - val_aux_output_loss: 0.3732\n",
      "Epoch 22/100\n",
      "347/363 [===========================>..] - ETA: 0s - loss: 0.2993 - output_loss: 0.2929 - aux_output_loss: 0.3569\n",
      "Epoch 22: val_loss did not improve from 0.31137\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2981 - output_loss: 0.2917 - aux_output_loss: 0.3560 - val_loss: 0.3193 - val_output_loss: 0.3136 - val_aux_output_loss: 0.3704\n",
      "Epoch 23/100\n",
      "353/363 [============================>.] - ETA: 0s - loss: 0.3019 - output_loss: 0.2958 - aux_output_loss: 0.3563\n",
      "Epoch 23: val_loss improved from 0.31137 to 0.31082, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.3008 - output_loss: 0.2947 - aux_output_loss: 0.3552 - val_loss: 0.3108 - val_output_loss: 0.3049 - val_aux_output_loss: 0.3640\n",
      "Epoch 24/100\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.2981 - output_loss: 0.2918 - aux_output_loss: 0.3552\n",
      "Epoch 24: val_loss did not improve from 0.31082\n",
      "363/363 [==============================] - 3s 7ms/step - loss: 0.2976 - output_loss: 0.2913 - aux_output_loss: 0.3548 - val_loss: 0.3146 - val_output_loss: 0.3088 - val_aux_output_loss: 0.3662\n",
      "Epoch 25/100\n",
      "349/363 [===========================>..] - ETA: 0s - loss: 0.2961 - output_loss: 0.2898 - aux_output_loss: 0.3524\n",
      "Epoch 25: val_loss did not improve from 0.31082\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2956 - output_loss: 0.2894 - aux_output_loss: 0.3517 - val_loss: 0.3150 - val_output_loss: 0.3091 - val_aux_output_loss: 0.3682\n",
      "Epoch 26/100\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.2944 - output_loss: 0.2882 - aux_output_loss: 0.3503\n",
      "Epoch 26: val_loss did not improve from 0.31082\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2950 - output_loss: 0.2887 - aux_output_loss: 0.3523 - val_loss: 0.3153 - val_output_loss: 0.3096 - val_aux_output_loss: 0.3669\n",
      "Epoch 27/100\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.2951 - output_loss: 0.2887 - aux_output_loss: 0.3528\n",
      "Epoch 27: val_loss did not improve from 0.31082\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2943 - output_loss: 0.2879 - aux_output_loss: 0.3519 - val_loss: 0.3115 - val_output_loss: 0.3057 - val_aux_output_loss: 0.3631\n",
      "Epoch 28/100\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.2969 - output_loss: 0.2909 - aux_output_loss: 0.3515\n",
      "Epoch 28: val_loss did not improve from 0.31082\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2958 - output_loss: 0.2898 - aux_output_loss: 0.3503 - val_loss: 0.3219 - val_output_loss: 0.3164 - val_aux_output_loss: 0.3721\n",
      "Epoch 29/100\n",
      "353/363 [============================>.] - ETA: 0s - loss: 0.2950 - output_loss: 0.2886 - aux_output_loss: 0.3520\n",
      "Epoch 29: val_loss improved from 0.31082 to 0.30912, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2960 - output_loss: 0.2897 - aux_output_loss: 0.3527 - val_loss: 0.3091 - val_output_loss: 0.3037 - val_aux_output_loss: 0.3581\n",
      "Epoch 30/100\n",
      "357/363 [============================>.] - ETA: 0s - loss: 0.2982 - output_loss: 0.2921 - aux_output_loss: 0.3528\n",
      "Epoch 30: val_loss did not improve from 0.30912\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2971 - output_loss: 0.2910 - aux_output_loss: 0.3520 - val_loss: 0.3252 - val_output_loss: 0.3205 - val_aux_output_loss: 0.3676\n",
      "Epoch 31/100\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.2955 - output_loss: 0.2892 - aux_output_loss: 0.3528\n",
      "Epoch 31: val_loss did not improve from 0.30912\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2947 - output_loss: 0.2884 - aux_output_loss: 0.3515 - val_loss: 0.3133 - val_output_loss: 0.3081 - val_aux_output_loss: 0.3604\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.3022 - output_loss: 0.2964 - aux_output_loss: 0.3541\n",
      "Epoch 32: val_loss did not improve from 0.30912\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.3022 - output_loss: 0.2964 - aux_output_loss: 0.3541 - val_loss: 0.3108 - val_output_loss: 0.3051 - val_aux_output_loss: 0.3621\n",
      "Epoch 33/100\n",
      "361/363 [============================>.] - ETA: 0s - loss: 0.2933 - output_loss: 0.2870 - aux_output_loss: 0.3496\n",
      "Epoch 33: val_loss did not improve from 0.30912\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2936 - output_loss: 0.2873 - aux_output_loss: 0.3501 - val_loss: 0.3173 - val_output_loss: 0.3119 - val_aux_output_loss: 0.3665\n",
      "Epoch 34/100\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.2952 - output_loss: 0.2889 - aux_output_loss: 0.3519\n",
      "Epoch 34: val_loss did not improve from 0.30912\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2954 - output_loss: 0.2892 - aux_output_loss: 0.3515 - val_loss: 0.3123 - val_output_loss: 0.3068 - val_aux_output_loss: 0.3623\n",
      "Epoch 35/100\n",
      "359/363 [============================>.] - ETA: 0s - loss: 0.2916 - output_loss: 0.2851 - aux_output_loss: 0.3498\n",
      "Epoch 35: val_loss did not improve from 0.30912\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2920 - output_loss: 0.2856 - aux_output_loss: 0.3493 - val_loss: 0.3108 - val_output_loss: 0.3054 - val_aux_output_loss: 0.3589\n",
      "Epoch 36/100\n",
      "358/363 [============================>.] - ETA: 0s - loss: 0.2912 - output_loss: 0.2849 - aux_output_loss: 0.3485\n",
      "Epoch 36: val_loss did not improve from 0.30912\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2923 - output_loss: 0.2860 - aux_output_loss: 0.3491 - val_loss: 0.3093 - val_output_loss: 0.3034 - val_aux_output_loss: 0.3621\n",
      "Epoch 37/100\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.2940 - output_loss: 0.2877 - aux_output_loss: 0.3504\n",
      "Epoch 37: val_loss improved from 0.30912 to 0.30893, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.2943 - output_loss: 0.2881 - aux_output_loss: 0.3499 - val_loss: 0.3089 - val_output_loss: 0.3038 - val_aux_output_loss: 0.3553\n",
      "Epoch 38/100\n",
      "361/363 [============================>.] - ETA: 0s - loss: 0.2935 - output_loss: 0.2873 - aux_output_loss: 0.3496\n",
      "Epoch 38: val_loss did not improve from 0.30893\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.2932 - output_loss: 0.2870 - aux_output_loss: 0.3493 - val_loss: 0.3226 - val_output_loss: 0.3182 - val_aux_output_loss: 0.3617\n",
      "Epoch 39/100\n",
      "353/363 [============================>.] - ETA: 0s - loss: 0.2914 - output_loss: 0.2853 - aux_output_loss: 0.3469\n",
      "Epoch 39: val_loss did not improve from 0.30893\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2926 - output_loss: 0.2865 - aux_output_loss: 0.3482 - val_loss: 0.3105 - val_output_loss: 0.3052 - val_aux_output_loss: 0.3581\n",
      "Epoch 40/100\n",
      "351/363 [============================>.] - ETA: 0s - loss: 0.2945 - output_loss: 0.2882 - aux_output_loss: 0.3511\n",
      "Epoch 40: val_loss improved from 0.30893 to 0.30655, saving model to my_keras_model.h5\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2918 - output_loss: 0.2855 - aux_output_loss: 0.3486 - val_loss: 0.3066 - val_output_loss: 0.3010 - val_aux_output_loss: 0.3561\n",
      "Epoch 41/100\n",
      "359/363 [============================>.] - ETA: 0s - loss: 0.2940 - output_loss: 0.2877 - aux_output_loss: 0.3500\n",
      "Epoch 41: val_loss did not improve from 0.30655\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2930 - output_loss: 0.2867 - aux_output_loss: 0.3490 - val_loss: 0.3129 - val_output_loss: 0.3074 - val_aux_output_loss: 0.3627\n",
      "Epoch 42/100\n",
      "359/363 [============================>.] - ETA: 0s - loss: 0.2943 - output_loss: 0.2883 - aux_output_loss: 0.3485\n",
      "Epoch 42: val_loss did not improve from 0.30655\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.2950 - output_loss: 0.2890 - aux_output_loss: 0.3491 - val_loss: 0.3120 - val_output_loss: 0.3068 - val_aux_output_loss: 0.3583\n",
      "Epoch 43/100\n",
      "361/363 [============================>.] - ETA: 0s - loss: 0.2938 - output_loss: 0.2875 - aux_output_loss: 0.3498\n",
      "Epoch 43: val_loss did not improve from 0.30655\n",
      "363/363 [==============================] - 2s 6ms/step - loss: 0.2932 - output_loss: 0.2870 - aux_output_loss: 0.3493 - val_loss: 0.3070 - val_output_loss: 0.3013 - val_aux_output_loss: 0.3583\n",
      "Epoch 44/100\n",
      "356/363 [============================>.] - ETA: 0s - loss: 0.2919 - output_loss: 0.2857 - aux_output_loss: 0.3483\n",
      "Epoch 44: val_loss did not improve from 0.30655\n",
      "363/363 [==============================] - 2s 7ms/step - loss: 0.2910 - output_loss: 0.2848 - aux_output_loss: 0.3470 - val_loss: 0.3129 - val_output_loss: 0.3074 - val_aux_output_loss: 0.3620\n",
      "Epoch 45/100\n",
      "351/363 [============================>.] - ETA: 0s - loss: 0.2910 - output_loss: 0.2849 - aux_output_loss: 0.3458\n",
      "Epoch 45: val_loss did not improve from 0.30655\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2910 - output_loss: 0.2849 - aux_output_loss: 0.3465 - val_loss: 0.3210 - val_output_loss: 0.3155 - val_aux_output_loss: 0.3704\n",
      "Epoch 46/100\n",
      "361/363 [============================>.] - ETA: 0s - loss: 0.2917 - output_loss: 0.2855 - aux_output_loss: 0.3478\n",
      "Epoch 46: val_loss did not improve from 0.30655\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2915 - output_loss: 0.2853 - aux_output_loss: 0.3472 - val_loss: 0.3090 - val_output_loss: 0.3033 - val_aux_output_loss: 0.3605\n",
      "Epoch 47/100\n",
      "355/363 [============================>.] - ETA: 0s - loss: 0.2900 - output_loss: 0.2838 - aux_output_loss: 0.3459\n",
      "Epoch 47: val_loss did not improve from 0.30655\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2905 - output_loss: 0.2842 - aux_output_loss: 0.3472 - val_loss: 0.3127 - val_output_loss: 0.3073 - val_aux_output_loss: 0.3615\n",
      "Epoch 48/100\n",
      "354/363 [============================>.] - ETA: 0s - loss: 0.2918 - output_loss: 0.2855 - aux_output_loss: 0.3486\n",
      "Epoch 48: val_loss did not improve from 0.30655\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2903 - output_loss: 0.2839 - aux_output_loss: 0.3473 - val_loss: 0.3248 - val_output_loss: 0.3193 - val_aux_output_loss: 0.3747\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.2920 - output_loss: 0.2857 - aux_output_loss: 0.3484\n",
      "Epoch 49: val_loss did not improve from 0.30655\n",
      "363/363 [==============================] - 2s 4ms/step - loss: 0.2920 - output_loss: 0.2857 - aux_output_loss: 0.3484 - val_loss: 0.3137 - val_output_loss: 0.3085 - val_aux_output_loss: 0.3605\n",
      "Epoch 50/100\n",
      "360/363 [============================>.] - ETA: 0s - loss: 0.2902 - output_loss: 0.2841 - aux_output_loss: 0.3456\n",
      "Epoch 50: val_loss did not improve from 0.30655\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "363/363 [==============================] - 2s 5ms/step - loss: 0.2904 - output_loss: 0.2842 - aux_output_loss: 0.3459 - val_loss: 0.3183 - val_output_loss: 0.3129 - val_aux_output_loss: 0.3672\n",
      "Epoch 50: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs = 100, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]), callbacks=[modelcheckpoint_cb, earlystopping_cb])\n",
    "\n",
    "# no. of epochs can be set very high since training will stop automatically if no more progress.\n",
    "# no need to restore best model saved as EarlyStopping_cb will keep track of the best weights and restore them at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
